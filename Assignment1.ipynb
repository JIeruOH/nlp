{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DIgM6C9HYUhm"
   },
   "source": [
    "# Context-sensitive Spelling Correction\n",
    "\n",
    "The goal of the assignment is to implement context-sensitive spelling correction. The input of the code will be a set of text lines and the output will be the same lines with spelling mistakes fixed.\n",
    "\n",
    "Submit the solution of the assignment to Moodle as a link to your GitHub repository containing this notebook.\n",
    "\n",
    "Useful links:\n",
    "- [Norvig's solution](https://norvig.com/spell-correct.html)\n",
    "- [Norvig's dataset](https://norvig.com/big.txt)\n",
    "- [Ngrams data](https://www.ngrams.info/download_coca.asp)\n",
    "\n",
    "Grading:\n",
    "- 60 points - Implement spelling correction\n",
    "- 20 points - Justify your decisions\n",
    "- 20 points - Evaluate on a test set\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x-vb8yFOGRDF"
   },
   "source": [
    "## Implement context-sensitive spelling correction\n",
    "\n",
    "Your task is to implement context-sensitive spelling corrector using N-gram language model. The idea is to compute conditional probabilities of possible correction options. For example, the phrase \"dking sport\" should be fixed as \"doing sport\" not \"dying sport\", while \"dking species\" -- as \"dying species\".\n",
    "\n",
    "The best way to start is to analyze [Norvig's solution](https://norvig.com/spell-correct.html) and [N-gram Language Models](https://web.stanford.edu/~jurafsky/slp3/3.pdf).\n",
    "\n",
    "When solving this task, we expect you'll face (and successfully deal with) some problems or make up the ideas of the model improvement. Some of them are: \n",
    "\n",
    "- solving a problem of n-grams frequencies storing for a large corpus;\n",
    "- taking into account keyboard layout and associated misspellings;\n",
    "- efficiency improvement to make the solution faster;\n",
    "- ...\n",
    "\n",
    "Please don't forget to describe such cases, and what you decided to do with them, in the Justification section.\n",
    "\n",
    "##### IMPORTANT:  \n",
    "Your project should not be a mere code copy-paste from somewhere. You must provide:\n",
    "- Your implementation\n",
    "- Analysis of why the implemented approach is suggested\n",
    "- Improvements of the original approach that you have chosen to implement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "id": "MoQeEsZvHvvi",
    "ExecuteTime": {
     "end_time": "2025-02-25T20:33:24.205815600Z",
     "start_time": "2025-02-25T20:33:24.200297100Z"
    }
   },
   "outputs": [],
   "source": [
    "# Your code here\n",
    "import re\n",
    "from math import exp, log, e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "outputs": [],
   "source": [
    "def normalize(text, to_string=False):\n",
    "    # delete everything except words and numbers\n",
    "    text = re.findall(r'\\w+', text.lower())\n",
    "    if to_string:\n",
    "        text = ' '.join(text)\n",
    "    return text"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-25T20:33:25.445008500Z",
     "start_time": "2025-02-25T20:33:25.429219Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "outputs": [],
   "source": [
    "def create_stats(n=2):\n",
    "    stats = {}\n",
    "    word_set = set()\n",
    "    with open('fivegrams.txt') as f:\n",
    "        text = f.read().split('\\n')\n",
    "    for words in text:\n",
    "        words = words.split()\n",
    "        if len(words) != 6: break\n",
    "        cnt = int(words.pop(0))\n",
    "        word_set.update(words)\n",
    "        words = [0] * n + words + [0] * n\n",
    "        for i in range(n, len(words) - n):\n",
    "            bag = words[i - n:i] + words[i + 1:i + n + 1]\n",
    "            for _ in range(n):\n",
    "                bg = tuple(bag)\n",
    "                if bg not in stats:\n",
    "                    stats[bg] = {0: 0}\n",
    "                stats[bg][words[i]] = stats[bg].get(words[i], 0) + cnt\n",
    "                stats[bg][0] += cnt\n",
    "                bag.pop(0)\n",
    "                bag.pop()\n",
    "    return stats, word_set\n",
    "\n",
    "\n",
    "stats, word_set = create_stats()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-25T20:33:40.407939800Z",
     "start_time": "2025-02-25T20:33:25.435010700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "outputs": [],
   "source": [
    "def get_statistics(wrds):\n",
    "    bag = list(wrds)\n",
    "    candidates = {word: e for word in word_set}\n",
    "    while bag:\n",
    "        res = stats.get(tuple(bag))\n",
    "        if res:\n",
    "            sum = res[0] + 1\n",
    "            for word, num in res.items():\n",
    "                if word == 0: continue\n",
    "                candidates[word] = candidates[word] / (sum - num) * sum\n",
    "        bag.pop(0)\n",
    "        bag.pop()\n",
    "    return candidates"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-25T20:33:40.417652200Z",
     "start_time": "2025-02-25T20:33:40.409938500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "outputs": [],
   "source": [
    "def dist(word1, word2):\n",
    "    ln1 = len(word1) + 1\n",
    "    ln2 = len(word2) + 1\n",
    "    dst = [[0] * ln2 for _ in range(ln1)]\n",
    "    for i in range(ln1): dst[i][0] = i\n",
    "    for i in range(ln2): dst[0][i] = i\n",
    "    for i in range(1, ln1):\n",
    "        for j in range(1, ln2):\n",
    "            dst[i][j] = min(dst[i][j - 1], dst[i - 1][j], dst[i - 1][j - 1])\n",
    "            if word1[i - 1] == word2[j - 1]:\n",
    "                dst[i][j] = dst[i - 1][j - 1]\n",
    "            else:\n",
    "                dst[i][j] = min(dst[i - 1][j], dst[i][j - 1], dst[i - 1][j - 1]) + 1\n",
    "    return dst[-1][-1]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-25T20:33:40.424229200Z",
     "start_time": "2025-02-25T20:33:40.415652900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "outputs": [],
   "source": [
    "def correct_word(wrds):\n",
    "    i = len(wrds) // 2\n",
    "    distances = {}\n",
    "    for word in word_set:\n",
    "        distances[word] = dist(word, wrds[i])\n",
    "    wrds.pop(i)\n",
    "    stat = get_statistics(wrds)\n",
    "    stat = max((log(stat[word]) * exp(-distances[word]), word) for word in stat)\n",
    "    return stat[1]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-25T20:33:40.434574600Z",
     "start_time": "2025-02-25T20:33:40.424229200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "outputs": [],
   "source": [
    "def correct_text(text, n=2):\n",
    "    text = normalize(text)\n",
    "    text = [0] * n + text + [0] * n\n",
    "    for i in range(n, len(text) - n):\n",
    "        if text[i] not in word_set:\n",
    "            text[i] = correct_word(text[i - n:i + n + 1])\n",
    "    return ' '.join(text[n:len(text) - n])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-25T20:33:40.453763400Z",
     "start_time": "2025-02-25T20:33:40.434574600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "outputs": [
    {
     "data": {
      "text/plain": "'the forest was alive with the sounds'"
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_text('tve forest was alive wth the saunds')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-25T20:33:41.864348100Z",
     "start_time": "2025-02-25T20:33:40.446762400Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oML-5sJwGRLE"
   },
   "source": [
    "## Justify your decisions\n",
    "\n",
    "Write down justificaitons for your implementation choices. For example, these choices could be:\n",
    "- Which ngram dataset to use\n",
    "- Which weights to assign for edit1, edit2 or absent words probabilities\n",
    "- Beam search parameters\n",
    "- etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6Xb_twOmVsC6"
   },
   "source": [
    "*Your text here...*"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Dataset\n",
    "The dataset of fivegrams was used for this task.\n",
    "This dataset contains >1M lines of fivegrams and >25K unique words.\n",
    "## Algorithm\n",
    "#### Statistics\n",
    "For this task were used different levels of n-grams: 3-grams, 5-grams, ..., (n * 2 + 1) - grams(n chosen by user, in this code used n = 2).\n",
    "Each n-gram consists of a context words on the left and on the right and the target word in the center, contextual words are used as keys and target words with their count as values.\n",
    "\n",
    "Example:\n",
    "\"a couple of days later\"\n",
    "\"a couple\" is left context and \"days later\" is right context\n",
    "(couple, days): {of: 42} for 3-grams\n",
    "(a, couple, days, later): {of: 24} for 5-grams\n",
    "\n",
    "for target word \"days\" we have not enough words, so we add 0 paddings.\n",
    "(couple, of, later, 0): {days: 34}\n",
    "\n",
    "Using that we can see both sides of word.\n",
    "#### Probability\n",
    "When we see a word that is not in the list of existing words, we take its all n-gram contexts.\n",
    "\n",
    "Example:\n",
    "\"a couple of dys later\"\n",
    "contexts: (of, later), (couple, of, later, 0)\n",
    "\n",
    "At the the start all words have their own weight, which is initially equal to e.\n",
    "\n",
    "After that, taking into account the found contexts, we increase the weight of those words that are affected by these contexts. To do this, we find the sum of all the words for a given context(sum), as well as the number of specific words whose weight we want to increase(num).\n",
    "\n",
    "Next, we take the weight of the found word and divide it by (sum - num) / sum, pre-adding +1 to sum to avoid zero-division when there is only one type of word in the context and sum = num. It is also worth considering that 0 < (sum - num) / sum <= 1, so if we found context with given word, its weight will be increased depending on the frequency with which a given word appears in a given context. Thus, if there is no context, we do not do anything with the weight of the words, and if there is a deeper context, we continue to increase the weight, so words with a deeper context will have more weight. This allows us to process contexts of any depth without affecting words that do not have them.\n",
    "\n",
    "After that, we find the Levenshtein distance from the unidentified word to the existing words, that will help us to find the lexographically closest words and rely less on context.\n",
    "\n",
    "Finally, the total weight is calculated using the formula: log(weight of word) * exp(-Levenshtein distance).\n",
    "log(weight of word) to get rid of oversaturated samples that will give out too much weight, also weigh of word >= e, so log(weight of word) >= 1.\n",
    "exp(-Levenshtein distance) to increase the weight of words that are close lexographically, correcting several letters instead of selecting words based heavily on context\n",
    " "
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "46rk65S4GRSe"
   },
   "source": [
    "## Evaluate on a test set\n",
    "\n",
    "Your task is to generate a test set and evaluate your work. You may vary the noise probability to generate different datasets with varying compexity (or just take another dataset). Compare your solution to the Norvig's corrector, and report the accuracies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "id": "OwZWaX9VVs7B",
    "ExecuteTime": {
     "end_time": "2025-02-25T20:34:04.134027300Z",
     "start_time": "2025-02-25T20:34:02.034042200Z"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "def words(text): return re.findall(r'\\w+', text.lower())\n",
    "\n",
    "\n",
    "WORDS = Counter(words(open('fivegrams.txt').read()))\n",
    "\n",
    "\n",
    "def Norwig(text):\n",
    "    def P(word, N=sum(WORDS.values())):\n",
    "        \"Probability of `word`.\"\n",
    "        return WORDS[word] / N\n",
    "\n",
    "    def correction(word):\n",
    "        \"Most probable spelling correction for word.\"\n",
    "        return max(candidates(word), key=P)\n",
    "\n",
    "    def candidates(word):\n",
    "        \"Generate possible spelling corrections for word.\"\n",
    "        return (known([word]) or known(edits1(word)) or known(edits2(word)) or [word])\n",
    "\n",
    "    def known(words):\n",
    "        \"The subset of `words` that appear in the dictionary of WORDS.\"\n",
    "        return set(w for w in words if w in WORDS)\n",
    "\n",
    "    def edits1(word):\n",
    "        \"All edits that are one edit away from `word`.\"\n",
    "        letters = 'abcdefghijklmnopqrstuvwxyz'\n",
    "        splits = [(word[:i], word[i:]) for i in range(len(word) + 1)]\n",
    "        deletes = [L + R[1:] for L, R in splits if R]\n",
    "        transposes = [L + R[1] + R[0] + R[2:] for L, R in splits if len(R) > 1]\n",
    "        replaces = [L + c + R[1:] for L, R in splits if R for c in letters]\n",
    "        inserts = [L + c + R for L, R in splits for c in letters]\n",
    "        return set(deletes + transposes + replaces + inserts)\n",
    "\n",
    "    def edits2(word):\n",
    "        \"All edits that are two edits away from `word`.\"\n",
    "        return (e2 for e1 in edits1(word) for e2 in edits1(e1))\n",
    "\n",
    "    return ' '.join(correction(i) for i in text.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "outputs": [
    {
     "data": {
      "text/plain": "'the forest was alive with the sounds'"
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Norwig('tve forest wos alive with the saunds')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-25T20:34:04.145381800Z",
     "start_time": "2025-02-25T20:34:04.134027300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "outputs": [],
   "source": [
    "# Your code here\n",
    "with open('test.txt') as f:\n",
    "    sentences = [normalize(sent, True) for sent in f.read().split('.') if sent != '']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-25T20:34:04.684256500Z",
     "start_time": "2025-02-25T20:34:04.671448500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "outputs": [],
   "source": [
    "from random import random, randint\n",
    "\n",
    "\n",
    "def ruined_sentence(text, p=0.3):\n",
    "    text = text.split()\n",
    "    for i in range(len(text)):\n",
    "        if random() > p: continue\n",
    "        for j in range(round(6 - log(randint(2, 32), 2))):\n",
    "            rnd = random()\n",
    "            text[i] = list(text[i])\n",
    "            k = randint(0, len(text[i]) - 1)\n",
    "            if rnd < 0.33 and len(text[i]) > 1:\n",
    "                text[i].pop(k)\n",
    "            elif rnd < 0.66:\n",
    "                text[i].insert(k, chr(randint(ord('a'), ord('z'))))\n",
    "            else:\n",
    "                text[i][k] = chr(randint(ord('a'), ord('z')))\n",
    "            text[i] = ''.join(text[i])\n",
    "    return ' '.join(text)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-25T20:34:05.291901700Z",
     "start_time": "2025-02-25T20:34:05.278109300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "outputs": [
    {
     "data": {
      "text/plain": "'te forest was alive with the sounds of nature ja symphony of chirkspng birds rustling leaves aund whpze occasional eknfa of a twig underfoot'"
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ruined_sentence(sentences[0])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-25T20:34:07.052020200Z",
     "start_time": "2025-02-25T20:34:07.043077Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original\n",
      "the forest was alive with the sounds of nature a symphony of chirping birds rustling leaves and the occasional snap of a twig underfoot\n",
      "With mistakes\n",
      "hm forest was alive with be okcnds of nmalqri a symphony of chirping birds rustling leaves uanc the mocaasional srap of wt qti underfoot\n",
      "Our accuracy: 0.5833\n",
      "hm forest was alive with be kinds of nmai a symphony of chipping birds rustling leaves anc the occasional wrap of wt qui underwood\n",
      "Norwig accuracy: 0.5833\n",
      "hm forest was alive with be kinds of nmalqri a symphony of chipping birds rustling leaves anc the occasional wrap of wt qui underwood\n",
      "\n",
      "Original\n",
      "the air was thick with the earthy scent of moss and damp soil a testament to the recent rain that had swept through the area\n",
      "With mistakes\n",
      "the wair was fhicfk with the earthy scent of moss apqd damp soil vz testament to the recent gin iat ha swept atrouh fthe area\n",
      "Our accuracy: 0.72\n",
      "the air was thick with the earthly scent of moss tpwd damp soil vu testament to the recent gin wiat ha swept trout the area\n",
      "Norwig accuracy: 0.72\n",
      "the war was thick with the earth scent of moss and damp soil v testament to the recent gin it ha swept trout the area\n",
      "\n",
      "Original\n",
      "sunlight filtered through the dense canopy above casting dappled shadows on the forest floor\n",
      "With mistakes\n",
      "sunlight filtered through the dense canopy above casting dappled shadqs on the forest fezoozr\n",
      "Our accuracy: 0.8571\n",
      "sunlight filtered through the dense canopy above casting tapped shades on the forest floor\n",
      "Norwig accuracy: 0.7857\n",
      "sunlight filtered through the dense canopy above casting applied shades on the forest fezoozr\n",
      "\n",
      "Original\n",
      "it was a place untouched by time where the worries of the modern world seemed to fade into insignificance\n",
      "With mistakes\n",
      "it was t place untouched bv time where hthte worries of the kmkodern world seemed qgfto fade into insignificance\n",
      "Our accuracy: 0.6842\n",
      "it was t place touched v time where thee worries of the modern world seemed zito fade into significance\n",
      "Norwig accuracy: 0.7368\n",
      "it was t place touched be time where the worries of the modern world seemed qgfto fade into significance\n",
      "\n",
      "Original\n",
      "a narrow path wound its way through the trees barely visible beneath the overgrowth\n",
      "With mistakes\n",
      "a narrow wah wownd its ywfy through l rtreeas barely visible beneath the iovergrowth\n",
      "Our accuracy: 0.8571\n",
      "a narrow wh wound its way through x trees barely visible beneath the overgrowth\n",
      "Norwig accuracy: 0.7857\n",
      "a narrow was wound its way through l streets barely visible beneath the overgrowth\n",
      "\n",
      "Original\n",
      "it was a path that had been trodden by countless creatures both human and animal over the years\n",
      "With mistakes\n",
      "it wfs ed pat tmat had ben trodden qmy countless creatures bqih human and animal over tche years\n",
      "Our accuracy: 0.6667\n",
      "it was ed pat that had ben broaden my countless creatures qi human and animal over the years\n",
      "Norwig accuracy: 0.6111\n",
      "it wfs ed pat that had ben broaden my countless creatures big human and animal over the years\n",
      "\n",
      "Original\n",
      "each step forward revealed something newвђ a cluster of vibrant wildflowers a fallen log covered in a carpet of soft green moss or the distant glimpse of a deer cautiously observing from the safety of the underbrush\n",
      "With mistakes\n",
      "each stwep forfard revealed oethiqg newвђ ba mlustoer f vibranw wildflowers a fallen wls covered in a carpet usyf soft green moss or the dicctunt glimpse gf gx dieer cautieuzsly observing from the safety af tze underbrush\n",
      "Our accuracy: 0.5946\n",
      "each step forward revealed thing newt ya muster f vibrant willpower a fallen was covered in a carpet ussr soft green moss or the discount glimpse sf x diner cautiously observing from the safety sf toe underwrite\n",
      "Norwig accuracy: 0.8108\n",
      "each step forward revealed oethiqg new a cluster f vibrant wildflowers a fallen was covered in a carpet us soft green moss or the discount glimpse of go deer cautiously observing from the safety of the underbrush\n",
      "\n",
      "Original\n",
      "the forest was a place of endless discovery where every corner held a secret waiting to be uncovered\n",
      "With mistakes\n",
      "the forest was y place of endless discovery where every corner held a secret waiting to be uncoavered\n",
      "Our accuracy: 1.0\n",
      "the forest was a place of endless discovery where every corner held a secret waiting to be uncovered\n",
      "Norwig accuracy: 0.9444\n",
      "the forest was y place of endless discovery where every corner held a secret waiting to be uncovered\n",
      "\n",
      "Original\n",
      "as the path continued it led to a small clearing bathed in golden light\n",
      "With mistakes\n",
      "at the paye continued it lea to a small clearing bathd in golden light\n",
      "Our accuracy: 0.7143\n",
      "at the pays continued it lea to a small clearing baths in golden light\n",
      "Norwig accuracy: 0.7143\n",
      "at the pay continued it lea to a small clearing bath in golden light\n",
      "\n",
      "Original\n",
      "in the center of the clearing stood an ancient oak tree its gnarled branches stretching out like the arms of a wise old guardian\n",
      "With mistakes\n",
      "ibn the center of the clearing jsd pn ancient oak tree its gnaqed ranks stretching rt like the vrms o a wise old guardin\n",
      "Our accuracy: 0.7083\n",
      "in the center of the clearing isd un ancient oak tree its named ranks stretching rt like the arms o a wise old guarding\n",
      "Norwig accuracy: 0.75\n",
      "in the center of the clearing isd in ancient oak tree its named ranks stretching rt like the arms o a wise old guardian\n",
      "\n",
      "Original\n",
      "the tree s trunk was thick and sturdy its bark rough and weathered from centuries of standing tall against the elements\n",
      "With mistakes\n",
      "the tree l unk was tpick and sturdy its bark roh and weathered fom centuries of standing tall against the elements\n",
      "Our accuracy: 0.7143\n",
      "the tree x unk was thick and study its bark roy and weather yom centuries of standing tall against the elements\n",
      "Norwig accuracy: 0.6667\n",
      "the tree l unk was pick and study its bark row and weather for centuries of standing tall against the elements\n",
      "\n",
      "Original\n",
      "at its base a ring of mushrooms formed a perfect circle as if marking the tree as a place of magic and mystery\n",
      "With mistakes\n",
      "at its base o riung of mushrooms formd f perfect circle as if maiarkong the tcb abr a place of magic and mystery\n",
      "Our accuracy: 0.7391\n",
      "at its base o rung of mushrooms forms f perfect circle as if marking the tub air a place of magic and mystery\n",
      "Norwig accuracy: 0.7391\n",
      "at its base o ring of mushrooms form f perfect circle as if maiarkong the tub air a place of magic and mystery\n",
      "\n",
      "Original\n",
      "a stream meandered through the clearing its crystal clear waters glinting in the sunlight\n",
      "With mistakes\n",
      "a stcein meandered through the clearing tyts crystal ctlephr waters glinting in the sunlight\n",
      "Our accuracy: 0.6429\n",
      "a stein wandered through the clearing yes crystal stehr waters printing in the sunlight\n",
      "Norwig accuracy: 0.6429\n",
      "a stein wandered through the clearing this crystal ctlephr waters painting in the sunlight\n",
      "\n",
      "Original\n",
      "the gentle babbling of the stream added to the serene atmosphere creating a sense of peace that was almost palpable\n",
      "With mistakes\n",
      "the gete babbling op the stream added to the serene atmosphere creating a sense of peace thkt was vlmost palpable\n",
      "Our accuracy: 0.8\n",
      "the pete labeling up the stream added to the serena atmosphere creating a sense of peace that was almost palpable\n",
      "Norwig accuracy: 0.8\n",
      "the get gambling op the stream added to the selene atmosphere creating a sense of peace that was almost palpable\n",
      "\n",
      "Original\n",
      "a wooden bench worn smooth by years of use sat beside the stream inviting anyone who passed by to sit and rest awhile\n",
      "With mistakes\n",
      "a wooden bench worn smooth by years of ulie sat beside the stream inviting kanyne who passed aqey to sit and rest aghle\n",
      "Our accuracy: 0.8261\n",
      "a wooden bench worn smooth by years of lie sat beside the stream inviting wayne who passed trey to sit and rest agile\n",
      "Norwig accuracy: 0.8696\n",
      "a wooden bench worn smooth by years of lie sat beside the stream inviting anyone who passed they to sit and rest agile\n",
      "\n",
      "Original\n",
      "it was a place where one could lose themselves in thought surrounded by the beauty and tranquility of nature\n",
      "With mistakes\n",
      "vt wvrls a plabi wherwe one could sonue themselves in thought surrounded by the besuty and tranquility of nature\n",
      "Our accuracy: 0.7368\n",
      "wt worms a slab where one could zone themselves in thought surrounded by the beauty and fragility of nature\n",
      "Norwig accuracy: 0.8421\n",
      "t world a place where one could one themselves in thought surrounded by the beauty and tranquility of nature\n",
      "\n",
      "Original\n",
      "as the day wore on the light began to shift casting long shadows across the clearing\n",
      "With mistakes\n",
      "as the day wore on the uight began vo shift castbjng lng shadows across the clearing\n",
      "Our accuracy: 0.8125\n",
      "as the day wore on the tight began yo shift casting lng shadows across the clearing\n",
      "Norwig accuracy: 0.875\n",
      "as the day wore on the right began to shift casting lng shadows across the clearing\n",
      "\n",
      "Original\n",
      "the air grew cooler and the sounds of the forest began to change as nocturnal creatures stirred from their daytime slumber\n",
      "With mistakes\n",
      "the uar grew cooler and the sounds of the forest began tbx change ga noocturnal creatures stirred from thei daytime slumber\n",
      "Our accuracy: 0.7143\n",
      "the war grew cooler and the sounds of the forest began to change ga natural creatures starred from they daytime lumber\n",
      "Norwig accuracy: 0.6667\n",
      "the far grew cooler and the sounds of the forest began tax change ga noocturnal creatures starred from the daytime lumber\n",
      "\n",
      "Original\n",
      "the transition from day to night was a gradual one a gentle reminder of the cyclical nature of life\n",
      "With mistakes\n",
      "the trahsiion fruom day to night as vd gradxuat one a kente rempinker of tzhe cyclical nature of life\n",
      "Our accuracy: 0.7895\n",
      "the transition from day to night as vu graduate one a kent reminder of the cyclical nature of life\n",
      "Norwig accuracy: 0.7895\n",
      "the transition from day to night as v graduate one a kent reminder of the cyclical nature of life\n",
      "\n",
      "Original\n",
      "the forest with all its wonders was a place where time seemed to stand still yet it was also a place of constant change and renewal\n",
      "With mistakes\n",
      "the bforest with all its wonders was fa place wheremz time seemed to stand still iywt im was apko a place o costant change an renewal\n",
      "Our accuracy: 0.8462\n",
      "the forest with all its wonders was a place whereof time seemed to stand still yet im was also a place o constant change an renewal\n",
      "Norwig accuracy: 0.8462\n",
      "the forest with all its wonders was a place where time seemed to stand still it im was also a place o constant change an renewal\n",
      "\n",
      "Original\n",
      "leaving the clearing behind the path continued deeper into the forest leading to who knows where\n",
      "With mistakes\n",
      "leaving the clearing behind the path continued deeper into zhte forest eadxinmg to vswho knows where\n",
      "Our accuracy: 0.9375\n",
      "leaving the clearing behind the path continued deeper into the forest waxing to who knows where\n",
      "Norwig accuracy: 0.9375\n",
      "leaving the clearing behind the path continued deeper into the forest eadxinmg to who knows where\n",
      "\n",
      "Original\n",
      "it was a journey without a clear destination a reminder that sometimes the most meaningful experiences come from simply being present in the moment\n",
      "With mistakes\n",
      "it wd a journey without a clear destination a remeondenr that sojmeikks the most meaningfl experiences come from simply being present in the moment\n",
      "Our accuracy: 0.9583\n",
      "it wu a journey without a clear destination a reminder that sometimes the most meaningful experiences come from simply being present in the moment\n",
      "Norwig accuracy: 0.875\n",
      "it we a journey without a clear destination a remeondenr that sojmeikks the most meaningful experiences come from simply being present in the moment\n",
      "\n",
      "Original\n",
      "the forest was a place of solace and inspiration a sanctuary for those seeking refuge from the chaos of the world\n",
      "With mistakes\n",
      "zbh forest wcas a place of sllace and inspiration a anctuary zr hkons seeking refume from the chaos of tcwhe world\n",
      "Our accuracy: 0.8571\n",
      "the forest was a place of solace and inspiration a sanctuary zu tons seeking resume from the chaos of the world\n",
      "Norwig accuracy: 0.8095\n",
      "be forest was a place of solace and inspiration a sanctuary or sons seeking refuse from the chaos of the world\n",
      "\n",
      "Original\n",
      "and as the last rays of sunlight disappeared behind the trees the forest whispered its timeless secrets to those who were willing to listen\n",
      "With mistakes\n",
      "d as pe last craqyp kd sunlight disappeared behind the tkes the forest whispered its timeless secrets to those wtho oire willing gyto listen\n",
      "Our accuracy: 0.7083\n",
      "d as ye last crazy td sunlight disappeared behind the tres the forest whispered its tireless secrets to those who wire willing to listen\n",
      "Norwig accuracy: 0.7083\n",
      "d as pe last crazy kid sunlight disappeared behind the takes the forest whispered its tireless secrets to those who fire willing to listen\n"
     ]
    }
   ],
   "source": [
    "accuracy1 = accuracy2 = 0\n",
    "\n",
    "for sent in sentences:\n",
    "    print('Original')\n",
    "    print(sent)\n",
    "    original = sent.split()\n",
    "    sent = ruined_sentence(sent)\n",
    "    print('With mistakes')\n",
    "    print(sent)\n",
    "    res1 = correct_text(sent)\n",
    "    acc1 = round(sum(i == j for i, j in zip(original, res1.split())) / len(original), 4)\n",
    "    accuracy1 += acc1\n",
    "    print('Our accuracy:', acc1)\n",
    "    print(res1)\n",
    "    res2 = Norwig(sent)\n",
    "    acc2 = round(sum(i == j for i, j in zip(original, res2.split())) / len(original), 4)\n",
    "    accuracy2 += acc2\n",
    "    print('Norwig accuracy:', acc2)\n",
    "    print(res2)\n",
    "    print()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-25T20:38:02.568136200Z",
     "start_time": "2025-02-25T20:36:31.338698400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our overall accuracy: 0.7695\n",
      "Norwig overall accuracy: 0.7713\n"
     ]
    }
   ],
   "source": [
    "print('Our overall accuracy:', round(accuracy1 / len(sentences), 4))\n",
    "print('Norwig overall accuracy:', round(accuracy2 / len(sentences), 4))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-25T20:38:35.622074600Z",
     "start_time": "2025-02-25T20:38:35.612121400Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Useful resources (also included in the archive in moodle):\n",
    "\n",
    "1. [Possible dataset with N-grams](https://www.ngrams.info/download_coca.asp)\n",
    "2. [Damerau–Levenshtein distance](https://en.wikipedia.org/wiki/Damerau–Levenshtein_distance#:~:text=Informally%2C%20the%20Damerau–Levenshtein%20distance,one%20word%20into%20the%20other.)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
