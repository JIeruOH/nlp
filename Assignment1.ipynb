{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DIgM6C9HYUhm"
   },
   "source": [
    "# Context-sensitive Spelling Correction\n",
    "\n",
    "The goal of the assignment is to implement context-sensitive spelling correction. The input of the code will be a set of text lines and the output will be the same lines with spelling mistakes fixed.\n",
    "\n",
    "Submit the solution of the assignment to Moodle as a link to your GitHub repository containing this notebook.\n",
    "\n",
    "Useful links:\n",
    "- [Norvig's solution](https://norvig.com/spell-correct.html)\n",
    "- [Norvig's dataset](https://norvig.com/big.txt)\n",
    "- [Ngrams data](https://www.ngrams.info/download_coca.asp)\n",
    "\n",
    "Grading:\n",
    "- 60 points - Implement spelling correction\n",
    "- 20 points - Justify your decisions\n",
    "- 20 points - Evaluate on a test set\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x-vb8yFOGRDF"
   },
   "source": [
    "## Implement context-sensitive spelling correction\n",
    "\n",
    "Your task is to implement context-sensitive spelling corrector using N-gram language model. The idea is to compute conditional probabilities of possible correction options. For example, the phrase \"dking sport\" should be fixed as \"doing sport\" not \"dying sport\", while \"dking species\" -- as \"dying species\".\n",
    "\n",
    "The best way to start is to analyze [Norvig's solution](https://norvig.com/spell-correct.html) and [N-gram Language Models](https://web.stanford.edu/~jurafsky/slp3/3.pdf).\n",
    "\n",
    "When solving this task, we expect you'll face (and successfully deal with) some problems or make up the ideas of the model improvement. Some of them are: \n",
    "\n",
    "- solving a problem of n-grams frequencies storing for a large corpus;\n",
    "- taking into account keyboard layout and associated misspellings;\n",
    "- efficiency improvement to make the solution faster;\n",
    "- ...\n",
    "\n",
    "Please don't forget to describe such cases, and what you decided to do with them, in the Justification section.\n",
    "\n",
    "##### IMPORTANT:  \n",
    "Your project should not be a mere code copy-paste from somewhere. You must provide:\n",
    "- Your implementation\n",
    "- Analysis of why the implemented approach is suggested\n",
    "- Improvements of the original approach that you have chosen to implement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "id": "MoQeEsZvHvvi",
    "ExecuteTime": {
     "end_time": "2025-02-25T20:33:24.205815600Z",
     "start_time": "2025-02-25T20:33:24.200297100Z"
    }
   },
   "outputs": [],
   "source": [
    "# Your code here\n",
    "import re\n",
    "from math import exp, log, e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "outputs": [],
   "source": [
    "def normalize(text, to_string=False):\n",
    "    # delete everything except words and numbers\n",
    "    text = re.findall(r'\\w+', text.lower())\n",
    "    if to_string:\n",
    "        text = ' '.join(text)\n",
    "    return text"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-25T20:33:25.445008500Z",
     "start_time": "2025-02-25T20:33:25.429219Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "outputs": [],
   "source": [
    "def create_stats(n=2):\n",
    "    stats = {}\n",
    "    word_set = set()\n",
    "    # fivegrams is too large for github))\n",
    "    with open('fivegrams.txt') as f:\n",
    "        text = f.read().split('\\n')\n",
    "    for words in text:\n",
    "        words = words.split()\n",
    "        if len(words) != 6: break\n",
    "        cnt = int(words.pop(0))\n",
    "        word_set.update(words)\n",
    "        words = [0] * n + words + [0] * n\n",
    "        for i in range(n, len(words) - n):\n",
    "            bag = words[i - n:i] + words[i + 1:i + n + 1]\n",
    "            for _ in range(n):\n",
    "                bg = tuple(bag)\n",
    "                if bg not in stats:\n",
    "                    stats[bg] = {0: 0}\n",
    "                stats[bg][words[i]] = stats[bg].get(words[i], 0) + cnt\n",
    "                stats[bg][0] += cnt\n",
    "                bag.pop(0)\n",
    "                bag.pop()\n",
    "    return stats, word_set\n",
    "\n",
    "\n",
    "stats, word_set = create_stats()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-25T20:33:40.407939800Z",
     "start_time": "2025-02-25T20:33:25.435010700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "outputs": [],
   "source": [
    "def get_statistics(wrds):\n",
    "    bag = list(wrds)\n",
    "    candidates = {word: e for word in word_set}\n",
    "    while bag:\n",
    "        res = stats.get(tuple(bag))\n",
    "        if res:\n",
    "            sum = res[0] + 1\n",
    "            for word, num in res.items():\n",
    "                if word == 0: continue\n",
    "                candidates[word] = candidates[word] / (sum - num) * sum\n",
    "        bag.pop(0)\n",
    "        bag.pop()\n",
    "    return candidates"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-25T20:33:40.417652200Z",
     "start_time": "2025-02-25T20:33:40.409938500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "outputs": [],
   "source": [
    "def dist(word1, word2):\n",
    "    ln1 = len(word1) + 1\n",
    "    ln2 = len(word2) + 1\n",
    "    dst = [[0] * ln2 for _ in range(ln1)]\n",
    "    for i in range(ln1): dst[i][0] = i\n",
    "    for i in range(ln2): dst[0][i] = i\n",
    "    for i in range(1, ln1):\n",
    "        for j in range(1, ln2):\n",
    "            dst[i][j] = min(dst[i][j - 1], dst[i - 1][j], dst[i - 1][j - 1])\n",
    "            if word1[i - 1] == word2[j - 1]:\n",
    "                dst[i][j] = dst[i - 1][j - 1]\n",
    "            else:\n",
    "                dst[i][j] = min(dst[i - 1][j], dst[i][j - 1], dst[i - 1][j - 1]) + 1\n",
    "            if min(i, j) > 1 and word1[i - 1] == word2[j - 2] and word1[i - 2] == word2[j - 1]:\n",
    "                dst[i][j] = min(dst[i][j], dst[i - 2][j - 2] + (word1[i - 1] != word2[j - 1]))\n",
    "    return dst[-1][-1]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-25T20:46:28.832337600Z",
     "start_time": "2025-02-25T20:46:28.824821300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "outputs": [],
   "source": [
    "def correct_word(wrds):\n",
    "    i = len(wrds) // 2\n",
    "    distances = {}\n",
    "    for word in word_set:\n",
    "        distances[word] = dist(word, wrds[i])\n",
    "    wrds.pop(i)\n",
    "    stat = get_statistics(wrds)\n",
    "    stat = max((log(stat[word]) * exp(-distances[word]), word) for word in stat)\n",
    "    return stat[1]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-25T20:46:29.617610600Z",
     "start_time": "2025-02-25T20:46:29.613215500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "outputs": [],
   "source": [
    "def correct_text(text, n=2):\n",
    "    text = normalize(text)\n",
    "    text = [0] * n + text + [0] * n\n",
    "    for i in range(n, len(text) - n):\n",
    "        if text[i] not in word_set:\n",
    "            text[i] = correct_word(text[i - n:i + n + 1])\n",
    "    return ' '.join(text[n:len(text) - n])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-25T20:46:30.436198100Z",
     "start_time": "2025-02-25T20:46:30.425680600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "outputs": [
    {
     "data": {
      "text/plain": "'the forest was alive with the sounds'"
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_text('tve forest was alive wth the saunds')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-25T20:46:32.926396600Z",
     "start_time": "2025-02-25T20:46:30.920607400Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oML-5sJwGRLE"
   },
   "source": [
    "## Justify your decisions\n",
    "\n",
    "Write down justificaitons for your implementation choices. For example, these choices could be:\n",
    "- Which ngram dataset to use\n",
    "- Which weights to assign for edit1, edit2 or absent words probabilities\n",
    "- Beam search parameters\n",
    "- etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6Xb_twOmVsC6"
   },
   "source": [
    "*Your text here...*"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Dataset\n",
    "The dataset of fivegrams was used for this task.\n",
    "This dataset contains >1M lines of fivegrams and >25K unique words.\n",
    "## Algorithm\n",
    "#### Statistics\n",
    "For this task were used different levels of n-grams: 3-grams, 5-grams, ..., (n * 2 + 1) - grams(n chosen by user, in this code used n = 2).\n",
    "Each n-gram consists of a context words on the left and on the right and the target word in the center, contextual words are used as keys and target words with their count as values.\n",
    "\n",
    "Example:\n",
    "\"a couple of days later\"\n",
    "\"a couple\" is left context and \"days later\" is right context\n",
    "(couple, days): {of: 42} for 3-grams\n",
    "(a, couple, days, later): {of: 24} for 5-grams\n",
    "\n",
    "for target word \"days\" we have not enough words, so we add 0 paddings.\n",
    "(couple, of, later, 0): {days: 34}\n",
    "\n",
    "Using that we can see both sides of word.\n",
    "#### Probability\n",
    "When we see a word that is not in the list of existing words, we take its all n-gram contexts.\n",
    "\n",
    "Example:\n",
    "\"a couple of dys later\"\n",
    "contexts: (of, later), (couple, of, later, 0)\n",
    "\n",
    "At the the start all words have their own weight, which is initially equal to e.\n",
    "\n",
    "After that, taking into account the found contexts, we increase the weight of those words that are affected by these contexts. To do this, we find the sum of all the words for a given context(sum), as well as the number of specific words whose weight we want to increase(num).\n",
    "\n",
    "Next, we take the weight of the found word and divide it by (sum - num) / sum, pre-adding +1 to sum to avoid zero-division when there is only one type of word in the context and sum = num. It is also worth considering that 0 < (sum - num) / sum <= 1, so if we found context with given word, its weight will be increased depending on the frequency with which a given word appears in a given context. Thus, if there is no context, we do not do anything with the weight of the words, and if there is a deeper context, we continue to increase the weight, so words with a deeper context will have more weight. This allows us to process contexts of any depth without affecting words that do not have them.\n",
    "\n",
    "After that, we find the Levenshtein distance from the unidentified word to the existing words, that will help us to find the lexographically closest words and rely less on context.\n",
    "\n",
    "Finally, the total weight is calculated using the formula: log(weight of word) * exp(-Levenshtein distance).\n",
    "log(weight of word) to get rid of oversaturated samples that will give out too much weight, also weigh of word >= e, so log(weight of word) >= 1.\n",
    "exp(-Levenshtein distance) to increase the weight of words that are close lexographically, correcting several letters instead of selecting words based heavily on context\n",
    " "
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "46rk65S4GRSe"
   },
   "source": [
    "## Evaluate on a test set\n",
    "\n",
    "Your task is to generate a test set and evaluate your work. You may vary the noise probability to generate different datasets with varying compexity (or just take another dataset). Compare your solution to the Norvig's corrector, and report the accuracies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "id": "OwZWaX9VVs7B",
    "ExecuteTime": {
     "end_time": "2025-02-25T20:46:40.296987700Z",
     "start_time": "2025-02-25T20:46:38.353137500Z"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "def words(text): return re.findall(r'\\w+', text.lower())\n",
    "\n",
    "\n",
    "WORDS = Counter(words(open('fivegrams.txt').read()))\n",
    "\n",
    "\n",
    "def Norwig(text):\n",
    "    def P(word, N=sum(WORDS.values())):\n",
    "        \"Probability of `word`.\"\n",
    "        return WORDS[word] / N\n",
    "\n",
    "    def correction(word):\n",
    "        \"Most probable spelling correction for word.\"\n",
    "        return max(candidates(word), key=P)\n",
    "\n",
    "    def candidates(word):\n",
    "        \"Generate possible spelling corrections for word.\"\n",
    "        return (known([word]) or known(edits1(word)) or known(edits2(word)) or [word])\n",
    "\n",
    "    def known(words):\n",
    "        \"The subset of `words` that appear in the dictionary of WORDS.\"\n",
    "        return set(w for w in words if w in WORDS)\n",
    "\n",
    "    def edits1(word):\n",
    "        \"All edits that are one edit away from `word`.\"\n",
    "        letters = 'abcdefghijklmnopqrstuvwxyz'\n",
    "        splits = [(word[:i], word[i:]) for i in range(len(word) + 1)]\n",
    "        deletes = [L + R[1:] for L, R in splits if R]\n",
    "        transposes = [L + R[1] + R[0] + R[2:] for L, R in splits if len(R) > 1]\n",
    "        replaces = [L + c + R[1:] for L, R in splits if R for c in letters]\n",
    "        inserts = [L + c + R for L, R in splits for c in letters]\n",
    "        return set(deletes + transposes + replaces + inserts)\n",
    "\n",
    "    def edits2(word):\n",
    "        \"All edits that are two edits away from `word`.\"\n",
    "        return (e2 for e1 in edits1(word) for e2 in edits1(e1))\n",
    "\n",
    "    return ' '.join(correction(i) for i in text.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "outputs": [
    {
     "data": {
      "text/plain": "'the forest was alive with the sounds'"
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Norwig('tve forest wos alive with the saunds')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-25T20:46:40.796602800Z",
     "start_time": "2025-02-25T20:46:40.783803600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "outputs": [],
   "source": [
    "# Your code here\n",
    "with open('test.txt') as f:\n",
    "    sentences = [normalize(sent, True) for sent in f.read().split('.') if sent != '']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-25T20:46:41.204392700Z",
     "start_time": "2025-02-25T20:46:41.176432200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "outputs": [],
   "source": [
    "from random import random, randint\n",
    "\n",
    "\n",
    "def ruined_sentence(text, p=0.3):\n",
    "    text = text.split()\n",
    "    for i in range(len(text)):\n",
    "        if random() > p: continue\n",
    "        for j in range(round(6 - log(randint(2, 32), 2))):\n",
    "            rnd = random()\n",
    "            text[i] = list(text[i])\n",
    "            k = randint(0, len(text[i]) - 1)\n",
    "            if rnd < 0.33 and len(text[i]) > 1:\n",
    "                text[i].pop(k)\n",
    "            elif rnd < 0.66:\n",
    "                text[i].insert(k, chr(randint(ord('a'), ord('z'))))\n",
    "            else:\n",
    "                text[i][k] = chr(randint(ord('a'), ord('z')))\n",
    "            text[i] = ''.join(text[i])\n",
    "    return ' '.join(text)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-25T20:46:41.584439Z",
     "start_time": "2025-02-25T20:46:41.572923Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "outputs": [
    {
     "data": {
      "text/plain": "'the forent was alive with the snds pose atvkre a symphony of chirping birds rustling leaves and th occasional snap of a twig uderfoot'"
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ruined_sentence(sentences[0])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-25T20:46:42.305748700Z",
     "start_time": "2025-02-25T20:46:42.300265100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original\n",
      "the forest was alive with the sounds of nature a symphony of chirping birds rustling leaves and the occasional snap of a twig underfoot\n",
      "With mistakes\n",
      "the lfores was alivcl with the sounds of nature a symphony of chirping mgirub rustling leaves and the occasional snap of a twig underfoot\n",
      "Our accuracy: 0.8333\n",
      "the flores was alive with the sounds of nature a symphony of chipping virus rustling leaves and the occasional snap of a twig underwood\n",
      "Norwig accuracy: 0.8333\n",
      "the flores was alive with the sounds of nature a symphony of chipping mgirub rustling leaves and the occasional snap of a twig underwood\n",
      "\n",
      "Original\n",
      "the air was thick with the earthy scent of moss and damp soil a testament to the recent rain that had swept through the area\n",
      "With mistakes\n",
      "the air was thick with the earthy jcenwv of moss and dalmyp soil a tesamnt typo the recent rain that had swept through the area\n",
      "Our accuracy: 0.96\n",
      "the air was thick with the earthly scent of moss and damp soil a testament to the recent rain that had swept through the area\n",
      "Norwig accuracy: 0.88\n",
      "the air was thick with the earth jcenwv of moss and damp soil a testament type the recent rain that had swept through the area\n",
      "\n",
      "Original\n",
      "sunlight filtered through the dense canopy above casting dappled shadows on the forest floor\n",
      "With mistakes\n",
      "sunlight filtered thrug the dense anopy above casting dappled shadows on ttze forest floor\n",
      "Our accuracy: 0.9286\n",
      "sunlight filtered through the dense canopy above casting tapped shadows on the forest floor\n",
      "Norwig accuracy: 0.8571\n",
      "sunlight filtered shrug the dense canopy above casting applied shadows on the forest floor\n",
      "\n",
      "Original\n",
      "it was a place untouched by time where the worries of the modern world seemed to fade into insignificance\n",
      "With mistakes\n",
      "it was a place untouched vc me whela xtlhe worries of the modern woamsrld seemed to fade into insignificance\n",
      "Our accuracy: 0.7368\n",
      "it was a place touched vu me wield the worries of the modern world seemed to fade into significance\n",
      "Norwig accuracy: 0.6842\n",
      "it was a place touched v me when the worries of the modern woamsrld seemed to fade into significance\n",
      "\n",
      "Original\n",
      "a narrow path wound its way through the trees barely visible beneath the overgrowth\n",
      "With mistakes\n",
      "a narrow path wound titf woaay through thzlr trees barely visaidle beneath ho overgrmwth\n",
      "Our accuracy: 0.7857\n",
      "a narrow path wound zito worry through the trees barely visible beneath ho overgrowth\n",
      "Norwig accuracy: 0.7857\n",
      "a narrow path wound it way through their trees barely visible beneath ho overgrowth\n",
      "\n",
      "Original\n",
      "it was a path that had been trodden by countless creatures both human and animal over the years\n",
      "With mistakes\n",
      "it was tga pah a had been trodden by countless ceature bh hmmkan and animal over the ecrns\n",
      "Our accuracy: 0.6111\n",
      "it was twa tah a had been broaden by countless feature wh human and animal over the horns\n",
      "Norwig accuracy: 0.6111\n",
      "it was ta pay a had been broaden by countless feature be human and animal over the turns\n",
      "\n",
      "Original\n",
      "each step forward revealed something newвђ a cluster of vibrant wildflowers a fallen log covered in a carpet of soft green moss or the distant glimpse of a deer cautiously observing from the safety of the underbrush\n",
      "With mistakes\n",
      "each tep forward revealed something neowђ a cluster fof vibratt wildflowers a fallen log covered in a carpet of soft green moss r the dizmstoant glimpse oz a deer cautiously observipg fxm the safety or the lnzneerarush\n",
      "Our accuracy: 0.7568\n",
      "each utep forward revealed something now a cluster off vibrant willpower a fallen log covered in a carpet of soft green moss r the distant glimpse oz a deer cautiously observing xm the safety or the lazarus\n",
      "Norwig accuracy: 0.7838\n",
      "each top forward revealed something new a cluster of vibrant wildflowers a fallen log covered in a carpet of soft green moss r the dizmstoant glimpse oz a deer cautiously observing fm the safety or the lnzneerarush\n",
      "\n",
      "Original\n",
      "the forest was a place of endless discovery where every corner held a secret waiting to be uncovered\n",
      "With mistakes\n",
      "the forest was a paace puo endless discovery where fvery coccnhehe held a secret waiting to be uncovered\n",
      "Our accuracy: 0.8333\n",
      "the forest was a place quo endless discovery where very couches held a secret waiting to be uncovered\n",
      "Norwig accuracy: 0.8333\n",
      "the forest was a place put endless discovery where very coccnhehe held a secret waiting to be uncovered\n",
      "\n",
      "Original\n",
      "as the path continued it led to a small clearing bathed in golden light\n",
      "With mistakes\n",
      "rs e path continued it le to a mau clearing bathed in golkden light\n",
      "Our accuracy: 0.7143\n",
      "vs e path continued it le to a yau clearing bathed in golden light\n",
      "Norwig accuracy: 0.7143\n",
      "is e path continued it le to a may clearing bathed in golden light\n",
      "\n",
      "Original\n",
      "in the center of the clearing stood an ancient oak tree its gnarled branches stretching out like the arms of a wise old guardian\n",
      "With mistakes\n",
      "je the center of the clearing stod a ancient oo tree its gnaxrleyvd branches stretching wu ifk the arms of a wise old guardian\n",
      "Our accuracy: 0.7083\n",
      "je the center of the clearing stow a ancient zoo tree its unarmed branches stretching wu jfk the arms of a wise old guardian\n",
      "Norwig accuracy: 0.7083\n",
      "je the center of the clearing stop a ancient to tree its gnaxrleyvd branches stretching wu if the arms of a wise old guardian\n",
      "\n",
      "Original\n",
      "the tree s trunk was thick and sturdy its bark rough and weathered from centuries of standing tall against the elements\n",
      "With mistakes\n",
      "the tree s trunk was thick nd sturdy its bark rough and weathered from cenmturxes t standing tall against the elements\n",
      "Our accuracy: 0.8095\n",
      "the tree s trunk was thick und study its bark rough and weather from centuries t standing tall against the elements\n",
      "Norwig accuracy: 0.8571\n",
      "the tree s trunk was thick and study its bark rough and weather from centuries t standing tall against the elements\n",
      "\n",
      "Original\n",
      "at its base a ring of mushrooms formed a perfect circle as if marking the tree as a place of magic and mystery\n",
      "With mistakes\n",
      "at its base a rhg jbf mushokoms formejd ya perfect circle as if arkien the tree as a place of magic anpd mystery\n",
      "Our accuracy: 0.7826\n",
      "at its base a rug wb mushrooms formed ya perfect circle as if harkin the tree as a place of magic npd mystery\n",
      "Norwig accuracy: 0.8696\n",
      "at its base a rug of mushrooms formed ya perfect circle as if ariel the tree as a place of magic and mystery\n",
      "\n",
      "Original\n",
      "a stream meandered through the clearing its crystal clear waters glinting in the sunlight\n",
      "With mistakes\n",
      "a stream meadered ctheoegh the clearing its rysl clear wftsrs glinting in the sunlight\n",
      "Our accuracy: 0.7857\n",
      "a stream rendered through the clearing its rye clear waters printing in the sunlight\n",
      "Norwig accuracy: 0.7143\n",
      "a stream measured ctheoegh the clearing its rest clear waters painting in the sunlight\n",
      "\n",
      "Original\n",
      "the gentle babbling of the stream added to the serene atmosphere creating a sense of peace that was almost palpable\n",
      "With mistakes\n",
      "the uentle babbling m tth stream added to the seren atmosphere creating a sense of peace tvha was almosb palpable\n",
      "Our accuracy: 0.75\n",
      "the gentle labeling m ttc stream added to the siren atmosphere creating a sense of peace via was almost palpable\n",
      "Norwig accuracy: 0.75\n",
      "the gentle gambling m jth stream added to the seen atmosphere creating a sense of peace the was almost palpable\n",
      "\n",
      "Original\n",
      "a wooden bench worn smooth by years of use sat beside the stream inviting anyone who passed by to sit and rest awhile\n",
      "With mistakes\n",
      "a wooden bench worn smooth by years of kuse sat beside the stream inviting anyone ho passed by to sit and rres akwhtbe\n",
      "Our accuracy: 0.913\n",
      "a wooden bench worn smooth by years of use sat beside the stream inviting anyone ho passed by to sit and ures awhile\n",
      "Norwig accuracy: 0.8696\n",
      "a wooden bench worn smooth by years of use sat beside the stream inviting anyone ho passed by to sit and pres akwhtbe\n",
      "\n",
      "Original\n",
      "it was a place where one could lose themselves in thought surrounded by the beauty and tranquility of nature\n",
      "With mistakes\n",
      "it was a acoe where one could lose themselves in thought sulroundek by oh beauty and tranquility of nuctur\n",
      "Our accuracy: 0.8421\n",
      "it was a coe where one could lose themselves in thought surrounded by oh beauty and fragility of nature\n",
      "Norwig accuracy: 0.8421\n",
      "it was a acre where one could lose themselves in thought surrounded by oh beauty and tranquility of nuctur\n",
      "\n",
      "Original\n",
      "as the day wore on the light began to shift casting long shadows across the clearing\n",
      "With mistakes\n",
      "as the day wore on the lht bhegn o shift casting loyxg shadows across the clearing\n",
      "Our accuracy: 0.75\n",
      "as the day wore on the lt when o shift casting lyng shadows across the clearing\n",
      "Norwig accuracy: 0.8125\n",
      "as the day wore on the lot been o shift casting long shadows across the clearing\n",
      "\n",
      "Original\n",
      "the air grew cooler and the sounds of the forest began to change as nocturnal creatures stirred from their daytime slumber\n",
      "With mistakes\n",
      "the air grw cooler and the sounds o the foreut began to change as nocturnal creatures qstrred from their daytime slumbefr\n",
      "Our accuracy: 0.7619\n",
      "the air grow cooler and the sounds o the forest began to change as natural creatures stored from their daytime lumber\n",
      "Norwig accuracy: 0.8571\n",
      "the air grew cooler and the sounds o the forest began to change as nocturnal creatures stared from their daytime lumber\n",
      "\n",
      "Original\n",
      "the transition from day to night was a gradual one a gentle reminder of the cyclical nature of life\n",
      "With mistakes\n",
      "oe transition from y otjo night was a graduaal one a gentle reminder of the cyclical nature of life\n",
      "Our accuracy: 0.8947\n",
      "the transition from yo two night was a gradual one a gentle reminder of the cyclical nature of life\n",
      "Norwig accuracy: 0.8947\n",
      "of transition from y to night was a gradual one a gentle reminder of the cyclical nature of life\n",
      "\n",
      "Original\n",
      "the forest with all its wonders was a place where time seemed to stand still yet it was also a place of constant change and renewal\n",
      "With mistakes\n",
      "the forest with all it wonders was a place where tijme seepmed to stand still et it was also a lamce of constant change and rexnewayl\n",
      "Our accuracy: 0.8846\n",
      "the forest with all it wonders was a place where time seemed to stand still et it was also a lance of constant change and renewal\n",
      "Norwig accuracy: 0.8846\n",
      "the forest with all it wonders was a place where time seemed to stand still et it was also a lance of constant change and renewal\n",
      "\n",
      "Original\n",
      "leaving the clearing behind the path continued deeper into the forest leading to who knows where\n",
      "With mistakes\n",
      "leavng the clearing behind the path continued deeper into the forest leading to wypht knows where\n",
      "Our accuracy: 0.9375\n",
      "leaving the clearing behind the path continued deeper into the forest leading to yunt knows where\n",
      "Norwig accuracy: 0.9375\n",
      "leaving the clearing behind the path continued deeper into the forest leading to wypht knows where\n",
      "\n",
      "Original\n",
      "it was a journey without a clear destination a reminder that sometimes the most meaningful experiences come from simply being present in the moment\n",
      "With mistakes\n",
      "it was a okrnfey wlithout a ltraqw slstinftion a rreminder ltha sometimes dry most jmeaningul experiences come from simply being nteslent fgi the moment\n",
      "Our accuracy: 0.75\n",
      "it was a journey without a straw distinction a reminder utah sometimes dry most meaningful experiences come from simply being telest gi the moment\n",
      "Norwig accuracy: 0.7083\n",
      "it was a okrnfey without a straw slstinftion a reminder the sometimes dry most meaningful experiences come from simply being nteslent fbi the moment\n",
      "\n",
      "Original\n",
      "the forest was a place of solace and inspiration a sanctuary for those seeking refuge from the chaos of the world\n",
      "With mistakes\n",
      "hz forest was fo place of solace raud inspiration r sanctuary for those seeking refuge from the chaos of the world\n",
      "Our accuracy: 0.8571\n",
      "the forest was no place of solace rand inspiration r sanctuary for those seeking refuge from the chaos of the world\n",
      "Norwig accuracy: 0.8095\n",
      "he forest was to place of solace fraud inspiration r sanctuary for those seeking refuge from the chaos of the world\n",
      "\n",
      "Original\n",
      "and as the last rays of sunlight disappeared behind the trees the forest whispered its timeless secrets to those who were willing to listen\n",
      "With mistakes\n",
      "and o the last xoaus x zzulght disappeared behind the trees the forest whispered its timehless secrets to those who were willng o loisxtn\n",
      "Our accuracy: 0.7083\n",
      "and o the last roars x taught disappeared behind the trees the forest whispered its tireless secrets to those who were willing o poison\n",
      "Norwig accuracy: 0.7083\n",
      "and o the last focus x zzulght disappeared behind the trees the forest whispered its tireless secrets to those who were willing o loisxtn\n"
     ]
    }
   ],
   "source": [
    "accuracy1 = accuracy2 = 0\n",
    "\n",
    "for sent in sentences:\n",
    "    print('Original')\n",
    "    print(sent)\n",
    "    original = sent.split()\n",
    "    sent = ruined_sentence(sent)\n",
    "    print('With mistakes')\n",
    "    print(sent)\n",
    "    res1 = correct_text(sent)\n",
    "    acc1 = round(sum(i == j for i, j in zip(original, res1.split())) / len(original), 4)\n",
    "    accuracy1 += acc1\n",
    "    print('Our accuracy:', acc1)\n",
    "    print(res1)\n",
    "    res2 = Norwig(sent)\n",
    "    acc2 = round(sum(i == j for i, j in zip(original, res2.split())) / len(original), 4)\n",
    "    accuracy2 += acc2\n",
    "    print('Norwig accuracy:', acc2)\n",
    "    print(res2)\n",
    "    print()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-25T20:48:23.648725600Z",
     "start_time": "2025-02-25T20:46:42.961549700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our overall accuracy: 0.804\n",
      "Norwig overall accuracy: 0.8003\n"
     ]
    }
   ],
   "source": [
    "print('Our overall accuracy:', round(accuracy1 / len(sentences), 4))\n",
    "print('Norwig overall accuracy:', round(accuracy2 / len(sentences), 4))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-25T20:49:31.000609700Z",
     "start_time": "2025-02-25T20:49:30.992534200Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Useful resources (also included in the archive in moodle):\n",
    "\n",
    "1. [Possible dataset with N-grams](https://www.ngrams.info/download_coca.asp)\n",
    "2. [Damerau–Levenshtein distance](https://en.wikipedia.org/wiki/Damerau–Levenshtein_distance#:~:text=Informally%2C%20the%20Damerau–Levenshtein%20distance,one%20word%20into%20the%20other.)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
